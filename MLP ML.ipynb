{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a easier understanading process, we will go step by step instaed of pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame as df\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "proportion = 0.3848"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load training,testing,additional training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(loacation,predicted = True):\n",
    "    \"\"\"\n",
    "    load data from csv file, transform class 0 to label -1 for confidence processing \n",
    "    :loacation file path in system\n",
    "    :predited: check wheather ask for traning data or testing data\n",
    "    \"\"\"  \n",
    "    features = []\n",
    "    classification = []\n",
    "    with open(loacation) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            # ignore head  \n",
    "            if readCSV.line_num == 1:\n",
    "                continue\n",
    "            \n",
    "            features.append(row[1:4609])\n",
    "            # if ask for training data\n",
    "            if predicted:\n",
    "                # transform class 0 to -1    \n",
    "                if row[4609] == '0':\n",
    "                    classification.append(-1)\n",
    "                else:\n",
    "                    classification.append(1)\n",
    "    # store features\n",
    "    features = np.array(features)\n",
    "    CNN_features = np.array(features[...,:4096])\n",
    "    GIST_features = np.array(features[...,4096:])\n",
    "    return CNN_features,GIST_features,classification\n",
    "\n",
    "def loda_data():\n",
    "    \"\"\"\n",
    "    load training,testing,additional training data respect to CNN, GIST, class \n",
    "    \"\"\"  \n",
    "  \n",
    "    CNN_features,GIST_features,classification = load_csv('training.csv')\n",
    "    t_CNN_features,t_GIST_features, t_classification = load_csv('testing.csv',False)\n",
    "    ic_CNN_features, ic_GIST_features, ic_classification = load_csv('additional_training.csv')\n",
    "  \n",
    "    train = [CNN_features,GIST_features,classification]\n",
    "    test = [t_CNN_features,t_GIST_features]\n",
    "    ic_train = [ic_CNN_features, ic_GIST_features, ic_classification]\n",
    "    return train,test,ic_train\n",
    "\n",
    "# ic_train means incomplete data, train means complete data, similar as below varibale name\n",
    "train,test,ic_train = loda_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classification():\n",
    "    # store classfiction information\n",
    "    classification = train[2].copy()\n",
    "    ic_classification = ic_train[2].copy()\n",
    "\n",
    "    #concatenate traning class data and additional traning class data\n",
    "    # c_xxx mean the combination of traning data and additional traning  data\n",
    "    c_classification = np.concatenate((classification,ic_classification))\n",
    "    return classification,ic_classification,c_classification\n",
    "\n",
    "\n",
    "classification,ic_classification,c_classification = load_classification()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the proportion of different class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(c_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import confidence to change class label with regrad confidence of all 0 class data as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_confidence():\n",
    "    with open('annotation_confidence.csv') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for i,row in enumerate(readCSV):\n",
    "            if readCSV.line_num == 1:\n",
    "                continue\n",
    "            # complete training data\n",
    "            if i <= 247:\n",
    "                if (classification[i-1]) * float(row[1])*100 == -66:\n",
    "                    classification[i-1] = -100\n",
    "                else:\n",
    "                    classification[i-1] = (classification[i-1]) * float(row[1])*100\n",
    "            # incomplete training data        \n",
    "            elif (ic_classification[i-248]) * float(row[1])*100 == -66:\n",
    "                ic_classification[i-248] = -100\n",
    "            else:\n",
    "                ic_classification[i-248] = (ic_classification[i-248]) * float(row[1])*100\n",
    "            return np.concatenate((classification,ic_classification))\n",
    "        \n",
    "c_classification = apply_confidence()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(c_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignore all class 1 data with confidence 0.66 through specifying the number of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traing data\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "strategy = {100:113,66:0,-100:38}\n",
    "rus = RandomUnderSampler(sampling_strategy=strategy,random_state=0)\n",
    "new_feas, new_class = rus.fit_resample(train[0].copy(), classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addtional training dataa\n",
    "strategy = {100:1029,66:0,-100:288}\n",
    "rus = RandomUnderSampler(sampling_strategy=strategy,random_state=0)\n",
    "new_icfeas, new_iclass = rus.fit_resample(ic_train[0], ic_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer (complete missing value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate traing data and addtional training dataa\n",
    "features = np.concatenate((new_feas,new_icfeas))\n",
    "_class = np.concatenate((new_class,new_iclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use most frequent strategy based on obeserving CNN feature\n",
    "spi = SimpleImputer(strategy = 'most_frequent').fit(features.astype(float))\n",
    "c_features = spi.transform(features.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adopt on L1 sparse solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature shape: (1468, 4096)\n",
      "After feature selection, shape: (1468, 692)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\"\"\"\n",
    ":model: feature selection model is saved to apply on testing data\n",
    ":Selected_ctrain: complete total data after feature selection\n",
    "\"\"\"  \n",
    "lsvc = LinearSVC(C=0.11,penalty=\"l1\", dual=False).fit((c_features), _class)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "Selected_ctrain = model.transform((c_features))\n",
    "print('Original feature shape:',c_features.shape)\n",
    "print('After feature selection, shape:',Selected_ctrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under sampling ( balanced data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xingxing/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:968: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  \" removed in 0.25.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After under sampling, shape: (652, 692)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\"\"\"\n",
    ":X_resampled: resampled training data\n",
    ":y_resampled: resampled class of training data\n",
    "\"\"\"  \n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_resampled, y_resampled = cc.fit_sample(Selected_ctrain, _class)\n",
    "print('After under sampling, shape:',X_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP model created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "ML = MLPClassifier(alpha = 0.001, hidden_layer_sizes = 110,solver='lbfgs',random_state=1, max_iter=10000,learning_rate = 'adaptive',learning_rate_init = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes':[125,120,126,100,127]}\n",
    "clf = GridSearchCV(ML, parameters)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect the model exprssion ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(estimator,X_resampled,y_resampled,cv = 5,norm = None):\n",
    "    \"\"\"\n",
    "    cross-validation to improve the classifer performence, \n",
    "    print the average accuracy and each split accuracy.\n",
    "    :y: ground truth\n",
    "    :pred: predictions classifer made\n",
    "    \"\"\"  \n",
    "    from sklearn.model_selection import cross_validate\n",
    "    if norm != None:\n",
    "        X_resampled= minmax_scale(X_resampled)\n",
    "        X_new = minmax_scale(X_new)\n",
    "    cv_results = cross_validate(estimator, X_resampled, y_resampled ,cv = cv)\n",
    "    print(cv_results['test_score'])\n",
    "    print(sum(cv_results['test_score'])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72519084 0.80916031 0.77692308 0.68461538 0.79230769]\n",
      "0.7576394597768644\n"
     ]
    }
   ],
   "source": [
    "cv(ML,minmax_scale(X_resampled), y_resampled ,cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save csv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(estimator,x,y,test,directory, func = None,normal = None,):\n",
    "    \"\"\"\n",
    "    fit the model and save the prediction as csv file, alternatively set feature selection\n",
    "    model and data preprocessing model\n",
    "    transofrom the label changed by confidence back to normal class label\n",
    "    :estimator: the model used\n",
    "    :x: np.array same shape as y:training data\n",
    "    :y: np.array same shape as x:testing data\n",
    "    :func: feature selection model\n",
    "    :normal: data pre-processing model\n",
    "    :directory: string: file saving path\n",
    "    \"\"\" \n",
    "    import pandas as pd\n",
    "    if func != None:\n",
    "        test = func.transform(test)\n",
    "    if normal != None:\n",
    "        x = normal(x)\n",
    "    estimator.fit(x,y)\n",
    "    results = estimator.predict(test)\n",
    "    predictions = []\n",
    "    for i, prediction in enumerate(results):\n",
    "        if prediction > 0:\n",
    "            predictions.append([i+1,1])\n",
    "        else:\n",
    "            predictions.append([i+1,0])\n",
    "    df = pd.DataFrame(predictions,columns = ['ID','prediction'])\n",
    "    df.to_csv(directory,index = False)\n",
    "\n",
    "save_csv(ML,X_resampled,y_resampled,test[0].copy().astype(float),'c0.11 alpha =0.0001 100 results_data.csv',model,minmax_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, hinge_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification matched = 11465\n",
      "[[6858  111]\n",
      " [ 298 4607]]\n"
     ]
    }
   ],
   "source": [
    "def compare_current_best():\n",
    "    \"\"\"\n",
    "    compare the current results to current best results\n",
    "    print accuracy score between them\n",
    "    \"\"\" \n",
    "    pred = []\n",
    "    with open('c0.11 alpha =0.0001 100 results_data.csv') as csvfile:\n",
    "      readCSV = csv.reader(csvfile, delimiter=',')\n",
    "      for i,row in enumerate(readCSV):\n",
    "        for row in readCSV:\n",
    "            if readCSV.line_num == 1:\n",
    "                continue\n",
    "            pred.append(row[1])\n",
    "    old_re = []\n",
    "    with open('c0.11 alpha =0.0001 100 results_data.csv') as csvfile:\n",
    "      readCSV = csv.reader(csvfile, delimiter=',')\n",
    "      for i,row in enumerate(readCSV):\n",
    "        for row in readCSV:\n",
    "            if readCSV.line_num == 1:\n",
    "                continue\n",
    "            old_re.append(row[1])\n",
    "    print('Classification matched = %d' % accuracy_score(old_re, pred, normalize=False))\n",
    "    print(confusion_matrix(old_re,pred))     \n",
    "compare_current_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_auc(y,pred):\n",
    "    \"\"\"\n",
    "    calculate auc value to inspect model effect\n",
    "    :y: ground truth\n",
    "    :pred: predictions classifer made\n",
    "    \"\"\"  \n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
